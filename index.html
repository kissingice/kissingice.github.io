<!DOCTYPE html>
<html lang="zh_Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="KissingIce" />


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="KissingIce">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="KissingIce">
<meta property="article:author" content="KissingIce">
<meta name="twitter:card" content="summary">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="KissingIce" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">



    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>KissingIce</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<meta name="generator" content="Hexo 4.2.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">KissingIce</a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="/3185849736@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/c%E8%AF%AD%E8%A8%80/" rel="tag">c语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/" target="_blank" rel="noopener">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/" target="_blank" rel="noopener">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">KissingIce</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">KissingIce</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="/3185849736@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-python爬取网页图片" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/24/python%E7%88%AC%E5%8F%96%E7%BD%91%E9%A1%B5%E5%9B%BE%E7%89%87/" class="article-date">
      <time datetime="2020-03-24T12:35:59.000Z" itemprop="datePublished">2020-03-24</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/24/python%E7%88%AC%E5%8F%96%E7%BD%91%E9%A1%B5%E5%9B%BE%E7%89%87/">python爬取网页图片</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>完整代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import re</span><br><span class="line">import urllib</span><br><span class="line">import urllib.request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_html(url):</span><br><span class="line">    page &#x3D; urllib.request.urlopen(url)</span><br><span class="line">    html_a &#x3D; page.read()</span><br><span class="line">    return html_a.decode(&#39;utf-8&#39;)</span><br><span class="line"></span><br><span class="line">def get_img(url):</span><br><span class="line">    x &#x3D; 1        # 声明一个变量赋值</span><br><span class="line">    html_b &#x3D; get_html(url)</span><br><span class="line">    reg &#x3D; r&#39;https:&#x2F;&#x2F;[^\s]*?\.jpg&#39;</span><br><span class="line">    imgre &#x3D; re.compile(reg)  # 转换成一个正则对象</span><br><span class="line">    imglist &#x3D; imgre.findall(html_b)  # 表示在整个网页过滤出所有图片的地址，放在imgList中</span><br><span class="line">    path &#x3D; os.getcwd() + os.sep + &#39;image&#39;  # 设置图片的保存地址</span><br><span class="line">    if not os.path.isdir(path):</span><br><span class="line">        os.makedirs(path)  # 判断没有此路径则创建</span><br><span class="line">    paths &#x3D; path + &#39;\\&#39;  # 保存在test路径下</span><br><span class="line">    for imgurl in imglist:</span><br><span class="line">        urllib.request.urlretrieve(imgurl, &#39;&#123;0&#125;&#123;1&#125;.jpg&#39;.format(paths, x))  # 打开imgList,下载图片到本地</span><br><span class="line">        print(&#39;开始下载第%s张图片&#39;%x)</span><br><span class="line">        x &#x3D; x + 1</span><br><span class="line"></span><br><span class="line">url &#x3D; input(&quot;请输入网址&quot;)</span><br><span class="line">#url &#x3D; </span><br><span class="line">get_img(url)</span><br></pre></td></tr></table></figure>





      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-第3章分类" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/18/%E7%AC%AC3%E7%AB%A0%E5%88%86%E7%B1%BB/" class="article-date">
      <time datetime="2020-03-18T05:29:01.000Z" itemprop="datePublished">2020-03-18</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/18/%E7%AC%AC3%E7%AB%A0%E5%88%86%E7%B1%BB/">第3章分类</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>参考：作者的<a href="https://nbviewer.jupyter.org/github/ageron/handson-ml/tree/master/" target="_blank" rel="noopener">Jupyter Notebook</a><br><a href="https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/03_classification.ipynb" target="_blank" rel="noopener">Chapter 2 – End-to-end Machine Learning project</a></p>
<ol>
<li><p>获取MNIST数据集的代码：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    def sort_by_target(mnist):</span><br><span class="line">    reorder_train &#x3D; np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]</span><br><span class="line">    reorder_test &#x3D; np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]</span><br><span class="line">    mnist.data[:60000] &#x3D; mnist.data[reorder_train]</span><br><span class="line">    mnist.target[:60000] &#x3D; mnist.target[reorder_train]</span><br><span class="line">    mnist.data[60000:] &#x3D; mnist.data[reorder_test + 60000]</span><br><span class="line">    mnist.target[60000:] &#x3D; mnist.target[reorder_test + 60000]</span><br><span class="line">from sklearn.datasets import fetch_openml</span><br><span class="line">mnist &#x3D; fetch_openml(&#39;mnist_784&#39;, version&#x3D;1, cache&#x3D;True)</span><br><span class="line">mnist.target &#x3D; mnist.target.astype(np.int8) # fetch_openml() returns targets as strings</span><br><span class="line">sort_by_target(mnist) # fetch_openml() returns an unsorted dataset</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看这些数组</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#print(mnist[&quot;data&quot;], mnist[&quot;target&quot;])</span><br><span class="line">#print(mnist.data.shape)</span><br><span class="line">X, y &#x3D; mnist[&quot;data&quot;], mnist[&quot;target&quot;]</span><br><span class="line">#print(X.shape)</span><br><span class="line">#print(y.shape)</span><br><span class="line"></span><br><span class="line">some_digit &#x3D; X[36000]</span><br><span class="line">some_digit_image &#x3D; some_digit.reshape(28, 28)</span><br><span class="line">plt.imshow(some_digit_image, cmap &#x3D; mpl.cm.binary,</span><br><span class="line">        interpolation&#x3D;&quot;nearest&quot;)</span><br><span class="line">plt.axis(&quot;off&quot;)</span><br><span class="line">#plt.show()</span><br><span class="line">#print(y[36000])</span><br></pre></td></tr></table></figure>
</li>
<li><p>MNIST数据集中的部分数字图像</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def plot_digits(instances, images_per_row&#x3D;10, **options):</span><br><span class="line">    size &#x3D; 28</span><br><span class="line">    images_per_row &#x3D; min(len(instances), images_per_row)</span><br><span class="line">    images &#x3D; [instance.reshape(size,size) for instance in instances]</span><br><span class="line">    n_rows &#x3D; (len(instances) - 1) &#x2F;&#x2F; images_per_row + 1</span><br><span class="line">    row_images &#x3D; []</span><br><span class="line">    n_empty &#x3D; n_rows * images_per_row - len(instances)</span><br><span class="line">    images.append(np.zeros((size, size * n_empty)))</span><br><span class="line">    for row in range(n_rows):</span><br><span class="line">        rimages &#x3D; images[row * images_per_row : (row + 1) * images_per_row]</span><br><span class="line">        row_images.append(np.concatenate(rimages, axis&#x3D;1))</span><br><span class="line">    image &#x3D; np.concatenate(row_images, axis&#x3D;0)</span><br><span class="line">    plt.imshow(image, cmap &#x3D; mpl.cm.binary, **options)</span><br><span class="line">    plt.axis(&quot;off&quot;)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize&#x3D;(9,9))</span><br><span class="line">example_images &#x3D; np.r_[X[:12000:600], X[13000:30600:600], X[30600:60000:590]]</span><br><span class="line">plot_digits(example_images, images_per_row&#x3D;10)</span><br><span class="line">#save_fig(&quot;more_digits_plot&quot;)</span><br><span class="line">#plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>给数据集洗牌</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test &#x3D; X[:60000], X[60000:], y[:60000], y[60000:]</span><br><span class="line">shuffle_index &#x3D; np.random.permutation(60000)</span><br><span class="line">X_train, y_train &#x3D; X_train[shuffle_index], y_train[shuffle_index]</span><br></pre></td></tr></table></figure>
</li>
<li><p>训练一个二元分类器，为此分类任务创建目标向量：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train_5 &#x3D; (y_train &#x3D;&#x3D; 5)  # True for all 5s, False for all other digits.</span><br><span class="line">y_test_5 &#x3D; (y_test &#x3D;&#x3D; 5)</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建一个SGDClassifier(随机梯度下降分类器)并在整个训练集上进行训练：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import SGDClassifier</span><br><span class="line">sgd_clf &#x3D; SGDClassifier(max_iter&#x3D;5, tol&#x3D;-np.infty, random_state&#x3D;42)   #random_state&#x3D;42</span><br><span class="line">sgd_clf.fit(X_train, y_train_5)</span><br><span class="line">#print(sgd_clf.fit(X_train, y_train_5))</span><br><span class="line">#现在可以用它来检测数字5的图像了：</span><br><span class="line">sgd_clf.predict([some_digit])</span><br><span class="line">#print(sgd_clf.predict([some_digit]))</span><br></pre></td></tr></table></figure>
</li>
<li><p>交叉验证</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">cross_val_score(sgd_clf, X_train, y_train_5, cv&#x3D;3, scoring&#x3D;&quot;accuracy&quot;)</span><br><span class="line">print(cross_val_score(sgd_clf, X_train, y_train_5, cv&#x3D;3, scoring&#x3D;&quot;accuracy&quot;))</span><br><span class="line"></span><br><span class="line">#下面这段代码与前面的cross_val_score（）大致相同，并打印出相同的结果：</span><br><span class="line">from sklearn.model_selection import StratifiedKFold</span><br><span class="line">from sklearn.base import clone</span><br><span class="line">skfolds &#x3D; StratifiedKFold(n_splits&#x3D;3, random_state&#x3D;42)   #random_state&#x3D;42</span><br><span class="line">for train_index, test_index in skfolds.split(X_train, y_train_5):</span><br><span class="line">    clone_clf &#x3D; clone(sgd_clf)</span><br><span class="line">    X_train_folds &#x3D; X_train[train_index]</span><br><span class="line">    y_train_folds &#x3D; (y_train_5[train_index])</span><br><span class="line">    X_test_fold &#x3D; X_train[test_index]</span><br><span class="line">    y_test_fold &#x3D; (y_train_5[test_index])</span><br><span class="line"></span><br><span class="line">    clone_clf.fit(X_train_folds, y_train_folds)</span><br><span class="line">    y_pred &#x3D; clone_clf.predict(X_test_fold)</span><br><span class="line">    n_correct &#x3D; sum(y_pred &#x3D;&#x3D; y_test_fold)</span><br><span class="line">    print(n_correct &#x2F; len(y_pred))</span><br></pre></td></tr></table></figure>
</li>
<li><p>一个蠢笨的分类器(不是我说的)，它将每张图都分类成“非5”：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator</span><br><span class="line">class Never5Classifier(BaseEstimator):</span><br><span class="line">    def fit(self, X, y&#x3D;None):</span><br><span class="line">        pass</span><br><span class="line">    def predict(self, X):</span><br><span class="line">        return np.zeros((len(X), 1), dtype&#x3D;bool)</span><br><span class="line">#准确度</span><br><span class="line">never_5_clf &#x3D; Never5Classifier()</span><br><span class="line">print(cross_val_score(never_5_clf, X_train, y_train_5, cv&#x3D;3, scoring&#x3D;&quot;accuracy&quot;))</span><br></pre></td></tr></table></figure>
</li>
<li><p>混淆矩阵:评估分类器性能的更好方法是混淆矩阵。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_predict</span><br><span class="line">y_train_pred &#x3D; cross_val_predict(sgd_clf, X_train, y_train_5, cv&#x3D;3)</span><br><span class="line">#cross_val_predict（）函数同样执行K-fold交叉验证，但返回的不是评估分数，而是每个折叠的预测。这意味着对于每个实例都可以得到一个干净的预测</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">#confusion_matrix(y_train_5, y_train_pred)</span><br><span class="line">#print(confusion_matrix(y_train_5, y_train_pred))</span><br><span class="line">y_train_perfect_predictions &#x3D; y_train_5</span><br><span class="line">#print(confusion_matrix(y_train_5, y_train_perfect_predictions))</span><br></pre></td></tr></table></figure>
</li>
<li><p>精度和召回率</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#精度&#x3D;TP&#x2F;(TP+FP)：TP是真正类的数量，FP是假正类的数量。</span><br><span class="line">#召回率&#x3D;TP&#x2F;(TP+FN)：FN是假负类的数量。</span><br><span class="line">from sklearn.metrics import precision_score, recall_score</span><br><span class="line">print(precision_score(y_train_5, y_train_pred))  #精度4344 &#x2F; (4344 + 1307)</span><br><span class="line">print(recall_score(y_train_5, y_train_pred))  #召回率4344 &#x2F; (4344 + 1077)</span><br><span class="line"></span><br><span class="line">#F1分数：F1&#x3D;2&#x2F;（1&#x2F;精度+1&#x2F;召回率）&#x3D;TP&#x2F;(TP+(FN+FP)&#x2F;2)</span><br><span class="line">from sklearn.metrics import f1_score</span><br><span class="line">print(f1_score(y_train_5, y_train_pred))</span><br></pre></td></tr></table></figure>
</li>
<li><p>精度/召回率权衡：阈值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">y_scores &#x3D; sgd_clf.decision_function([some_digit])</span><br><span class="line">print(y_scores)</span><br><span class="line">threshold &#x3D; 0</span><br><span class="line">y_some_digit_pred &#x3D; (y_scores &gt; threshold)</span><br><span class="line">print(y_some_digit_pred)</span><br><span class="line">#提高阈值</span><br><span class="line">threshold &#x3D; 200000</span><br><span class="line">y_some_digit_pred_a &#x3D; (y_scores &gt; threshold)</span><br><span class="line">print(y_some_digit_pred_a)</span><br></pre></td></tr></table></figure>
</li>
<li><p>决定使用什么阈值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#获取训练集中所有实例的分数</span><br><span class="line">y_scores &#x3D; cross_val_predict(sgd_clf, X_train, y_train_5, cv&#x3D;3, method&#x3D;&quot;decision_function&quot;)</span><br><span class="line">#计算所有可能的阈值的精度和召回率</span><br><span class="line">from sklearn.metrics import precision_recall_curve</span><br><span class="line">precisions, recalls, thresholds &#x3D; precision_recall_curve(y_train_5, y_scores)</span><br><span class="line">#使用Matplotlib绘制精度和召回率相对于阈值的函数图</span><br><span class="line">def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):</span><br><span class="line">    plt.plot(thresholds, precisions[:-1], &quot;b--&quot;, label&#x3D;&quot;Precision&quot;)</span><br><span class="line">    plt.plot(thresholds, recalls[:-1], &quot;g-&quot;, label&#x3D;&quot;Recall&quot;)</span><br><span class="line">    plt.xlabel(&quot;Threshold&quot;)</span><br><span class="line">    plt.legend(loc&#x3D;&quot;upper left&quot;)</span><br><span class="line">    plt.ylim([0, 1])</span><br><span class="line">plt.figure(figsize&#x3D;(8, 4))</span><br><span class="line">plot_precision_recall_vs_threshold(precisions, recalls, thresholds)</span><br><span class="line">plt.xlim([-700000, 700000])</span><br><span class="line">plt.show()</span><br><span class="line">#print((y_train_pred &#x3D;&#x3D; (y_scores &gt; 0)).all())</span><br><span class="line">y_train_pred_90 &#x3D; (y_scores &gt; 70000)</span><br><span class="line">from sklearn.metrics import precision_score, recall_score</span><br><span class="line">print(precision_score(y_train_5, y_train_pred_90)) #精度</span><br><span class="line">print(recall_score(y_train_5, y_train_pred_90)) #召回率</span><br></pre></td></tr></table></figure>
</li>
<li><p>精度和召回率的函数图PR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def plot_precision_vs_recall(precisions, recalls):</span><br><span class="line">    plt.plot(recalls, precisions, &quot;b-&quot;, linewidth&#x3D;2)</span><br><span class="line">    plt.xlabel(&quot;Recall&quot;, fontsize&#x3D;16)</span><br><span class="line">    plt.ylabel(&quot;Precision&quot;, fontsize&#x3D;16)</span><br><span class="line">    plt.axis([0, 1, 0, 1])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize&#x3D;(8, 6))</span><br><span class="line">plot_precision_vs_recall(precisions, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>ROC曲线（受试者工作特征曲线）：真正类率和假正类率</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line">fpr, tpr, thresholds &#x3D; roc_curve(y_train_5, y_scores)</span><br><span class="line">def plot_roc_curve(fpr, tpr, label&#x3D;None):</span><br><span class="line">    plt.plot(fpr, tpr, linewidth&#x3D;2, label&#x3D;label)</span><br><span class="line">    plt.plot([0, 1], [0, 1], &#39;k--&#39;)</span><br><span class="line">    plt.axis([0, 1, 0, 1])</span><br><span class="line">    plt.xlabel(&#39;False Positive Rate&#39;, fontsize&#x3D;16)</span><br><span class="line">    plt.ylabel(&#39;True Positive Rate&#39;, fontsize&#x3D;16)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">plt.figure(figsize&#x3D;(8, 6))</span><br><span class="line">plot_roc_curve(fpr, tpr)</span><br><span class="line">plt.show()</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">print(roc_auc_score(y_train_5, y_scores))</span><br></pre></td></tr></table></figure>
</li>
<li><p>训练一个RandomForestClassifier分类器，并比较它和SGDClassifier分类器的ROC曲线和ROC AUC分数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">forest_clf &#x3D; RandomForestClassifier(n_estimators&#x3D;10, random_state&#x3D;42)</span><br><span class="line">y_probas_forest &#x3D; cross_val_predict(forest_clf, X_train, y_train_5, cv&#x3D;3, method&#x3D;&quot;predict_proba&quot;)</span><br><span class="line">y_scores_forest &#x3D; y_probas_forest[:, 1] # score &#x3D; proba of positive class</span><br><span class="line">fpr_forest, tpr_forest, thresholds_forest &#x3D; roc_curve(y_train_5,y_scores_forest)</span><br><span class="line">plt.figure(figsize&#x3D;(8, 6))</span><br><span class="line">plt.plot(fpr, tpr, &quot;b:&quot;, linewidth&#x3D;2, label&#x3D;&quot;SGD&quot;)</span><br><span class="line">plot_roc_curve(fpr_forest, tpr_forest, &quot;Random Forest&quot;)</span><br><span class="line">plt.legend(loc&#x3D;&quot;lower right&quot;, fontsize&#x3D;16)</span><br><span class="line">plt.show()</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">print(roc_auc_score(y_train_5, y_scores_forest))</span><br></pre></td></tr></table></figure>
</li>
<li><p>多类别分类器，用SGDClassifier试试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#用SGDClassifier试试：</span><br><span class="line">sgd_clf.fit(X_train, y_train)</span><br><span class="line">sgd_clf.predict([some_digit])</span><br><span class="line">#print(sgd_clf.predict([some_digit]))</span><br><span class="line">some_digit_scores &#x3D; sgd_clf.decision_function([some_digit])</span><br><span class="line">#print(some_digit_scores)</span><br><span class="line">#print(np.argmax(some_digit_scores))</span><br><span class="line">#print(sgd_clf.classes_)</span><br><span class="line">#print(sgd_clf.classes_[5])</span><br><span class="line"></span><br><span class="line">#下面这段代码使用OvO策略，基于SGDClassifier创建了一个多类别分类器：</span><br><span class="line">from sklearn.multiclass import OneVsOneClassifier</span><br><span class="line">ovo_clf &#x3D; OneVsOneClassifier(SGDClassifier(max_iter&#x3D;5, tol&#x3D;-np.infty, random_state&#x3D;42))</span><br><span class="line">ovo_clf.fit(X_train, y_train)</span><br><span class="line">ovo_clf.predict([some_digit])</span><br><span class="line">len(ovo_clf.estimators_)</span><br><span class="line">#print(ovo_clf.predict([some_digit]))</span><br><span class="line">#print(len(ovo_clf.estimators_))</span><br></pre></td></tr></table></figure>
</li>
<li><p>训练RandomForestClassifier</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">forest_clf.fit(X_train, y_train)</span><br><span class="line">#print(forest_clf.predict([some_digit]))</span><br><span class="line">#print(forest_clf.predict_proba([some_digit]))  #概率列表</span><br><span class="line">#print(cross_val_score(sgd_clf, X_train, y_train, cv&#x3D;3, scoring&#x3D;&quot;accuracy&quot;))  #准确率</span><br><span class="line">#将输入进行简单缩放</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">scaler &#x3D; StandardScaler()</span><br><span class="line">X_train_scaled &#x3D; scaler.fit_transform(X_train.astype(np.float64))</span><br><span class="line">#print(cross_val_score(sgd_clf, X_train_scaled, y_train, cv&#x3D;3, scoring&#x3D;&quot;accuracy&quot;))</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用Matplotlib的matshow（）函数来查看混淆矩阵</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred &#x3D; cross_val_predict(sgd_clf, X_train_scaled, y_train, cv&#x3D;3)</span><br><span class="line">conf_mx &#x3D; confusion_matrix(y_train, y_train_pred)</span><br><span class="line">#print(conf_mx)</span><br><span class="line">#使用Matplotlib的matshow（）函数来查看混淆矩阵的图像表示</span><br><span class="line">#plt.matshow(conf_mx, cmap&#x3D;plt.cm.gray)</span><br><span class="line">#save_fig(&quot;confusion_matrix_plot&quot;, tight_layout&#x3D;False)</span><br></pre></td></tr></table></figure>
</li>
<li><p>你需要将混淆矩阵中的每个值除以相应类别中的图片数量，这样你比较的就是错误率而不是错误的绝对值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">row_sums &#x3D; conf_mx.sum(axis&#x3D;1, keepdims&#x3D;True)</span><br><span class="line">norm_conf_mx &#x3D; conf_mx &#x2F; row_sums</span><br><span class="line">#用0填充对角线，只保留错误，重新绘制结果：</span><br><span class="line">np.fill_diagonal(norm_conf_mx, 0)</span><br><span class="line">plt.matshow(norm_conf_mx, cmap&#x3D;plt.cm.gray)</span><br><span class="line">#save_fig(&quot;confusion_matrix_errors_plot&quot;, tight_layout&#x3D;False)</span><br></pre></td></tr></table></figure>
</li>
<li><p>看看数字3和数字5的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cl_a, cl_b &#x3D; 3, 5</span><br><span class="line">X_aa &#x3D; X_train[(y_train &#x3D;&#x3D; cl_a) &amp; (y_train_pred &#x3D;&#x3D; cl_a)]</span><br><span class="line">X_ab &#x3D; X_train[(y_train &#x3D;&#x3D; cl_a) &amp; (y_train_pred &#x3D;&#x3D; cl_b)]</span><br><span class="line">X_ba &#x3D; X_train[(y_train &#x3D;&#x3D; cl_b) &amp; (y_train_pred &#x3D;&#x3D; cl_a)]</span><br><span class="line">X_bb &#x3D; X_train[(y_train &#x3D;&#x3D; cl_b) &amp; (y_train_pred &#x3D;&#x3D; cl_b)]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize&#x3D;(8,8))</span><br><span class="line">plt.subplot(221); plot_digits(X_aa[:25], images_per_row&#x3D;5)</span><br><span class="line">plt.subplot(222); plot_digits(X_ab[:25], images_per_row&#x3D;5)</span><br><span class="line">plt.subplot(223); plot_digits(X_ba[:25], images_per_row&#x3D;5)</span><br><span class="line">plt.subplot(224); plot_digits(X_bb[:25], images_per_row&#x3D;5)</span><br><span class="line">#save_fig(&quot;error_analysis_digits_plot&quot;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>多标签分类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#这段代码会创建一个y_multilabel数组，其中包含两个数字图片的目标标签：第一个表示数字是否是大数（7、8、9），第二个表示是否为奇数。</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">y_train_large &#x3D; (y_train &gt;&#x3D; 7)</span><br><span class="line">y_train_odd &#x3D; (y_train % 2 &#x3D;&#x3D; 1)</span><br><span class="line">y_multilabel &#x3D; np.c_[y_train_large, y_train_odd]</span><br><span class="line"></span><br><span class="line">knn_clf &#x3D; KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(X_train, y_multilabel)</span><br><span class="line">#print(knn_clf.fit(X_train, y_multilabel))</span><br><span class="line">#下一行创建一个KNeighborsClassifier实例（它支持多标签分类，不是所有的分类器都支持），然后使用多个目标数组对它进行</span><br><span class="line">#训练。现在用它做一个预测，注意它输出的两个标签：</span><br><span class="line">knn_clf.predict([some_digit])    #数字5确实不大（False），为奇数（True）。</span><br><span class="line">#print(knn_clf.predict([some_digit]))</span><br></pre></td></tr></table></figure>
</li>
<li><p>下面这段代码计算所有标签的平均F1分数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import f1_score</span><br><span class="line">y_train_knn_pred &#x3D; cross_val_predict(knn_clf, X_train, y_multilabel, cv&#x3D;3, n_jobs&#x3D;-1)</span><br><span class="line">f1_score(y_multilabel, y_train_knn_pred, average&#x3D;&quot;macro&quot;)</span><br><span class="line">#print(f1_score(y_multilabel, y_train_knn_pred, average&#x3D;&quot;macro&quot;))</span><br></pre></td></tr></table></figure>
</li>
<li><p>多输出分类(多输出-多类别分类)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#还先从创建训练集和测试集开始，使用NumPy的randint（）函数</span><br><span class="line">#为MNIST图片的像素强度增加噪声。目标是将图片还原为原始图片：</span><br><span class="line">noise &#x3D; np.random.randint(0, 100, (len(X_train), 784))</span><br><span class="line">X_train_mod &#x3D; X_train + noise</span><br><span class="line">noise &#x3D; np.random.randint(0, 100, (len(X_test), 784))</span><br><span class="line">X_test_mod &#x3D; X_test + noise</span><br><span class="line">y_train_mod &#x3D; X_train</span><br><span class="line">y_test_mod &#x3D; X_test</span><br><span class="line"></span><br><span class="line">some_index &#x3D; 5500</span><br><span class="line">#plt.subplot(121); plot_digit(X_test_mod[some_index])</span><br><span class="line">#plt.subplot(122); plot_digit(y_test_mod[some_index])</span><br><span class="line">#save_fig(&quot;noisy_digit_example_plot&quot;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>清洗这张图片：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.fit(X_train_mod, y_train_mod)</span><br><span class="line">clean_digit &#x3D; knn_clf.predict([X_test_mod[some_index]])</span><br><span class="line">plot_digit(clean_digit)</span><br><span class="line">save_fig(&quot;cleaned_digit_example_plot&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-第2章端到端的机器学习项目" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/11/%E7%AC%AC2%E7%AB%A0%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/" class="article-date">
      <time datetime="2020-03-10T17:14:42.000Z" itemprop="datePublished">2020-03-11</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/11/%E7%AC%AC2%E7%AB%A0%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/">第2章端到端的机器学习项目</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>参考：作者的<a href="https://nbviewer.jupyter.org/github/ageron/handson-ml/tree/master/" target="_blank" rel="noopener">Jupyter Notebook</a><br><a href="https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb" target="_blank" rel="noopener">Chapter 2 – End-to-end Machine Learning project</a></p>
<ol>
<li><p>下载数据</p>
<ul>
<li>打开vscode，建立新的python文件，输入以下代码，下载housing.tgz文件，并将housing.csv解压到这个目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import tarfile</span><br><span class="line">from six.moves import urllib</span><br><span class="line"></span><br><span class="line">download_root &#x3D; &quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ageron&#x2F;handson-ml&#x2F;master&#x2F;&quot;</span><br><span class="line">HOUSING_PATH &#x3D; &quot;datasets&#x2F;housing&quot;</span><br><span class="line">HOUSING_URL &#x3D; download_root + HOUSING_PATH + &quot;&#x2F;housing.tgz&quot;</span><br><span class="line"></span><br><span class="line">def fetch_housing_data(housing_url&#x3D;HOUSING_URL,housing_path&#x3D;HOUSING_PATH):</span><br><span class="line">    if not os.path.isdir(housing_path):</span><br><span class="line">        os.makedirs(housing_path)</span><br><span class="line">    tgz_path &#x3D; os.path.join(housing_path, &quot;housing.tgz&quot;)</span><br><span class="line">    urllib.request.urlretrieve(housing_url, tgz_path)</span><br><span class="line">    housing_tgz &#x3D; tarfile.open(tgz_path)</span><br><span class="line">    housing_tgz.extractall(path&#x3D;housing_path)</span><br><span class="line">    housing_tgz.close()</span><br><span class="line"></span><br><span class="line">fetch_housing_data()</span><br></pre></td></tr></table></figure>
下载后可将函数注释</li>
</ul>
</li>
<li><p>快速查看数据结构<br>a) 使用pandas加载数据</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mport pandas as pd</span><br><span class="line">def load_housing_data(housing_path&#x3D;HOUSING_PATH):</span><br><span class="line">  csv_path &#x3D; os.path.join(housing_path, &quot;housing.csv&quot;)</span><br><span class="line">  return pd.read_csv(csv_path)</span><br></pre></td></tr></table></figure>
<p> 函数返回一个包含所有数据的Pandas DataFrame对象</p>
<p>b) 调用DataFrames的head()方法查看前5行数据（由于使用的是vscode所以会和书里有所不同）,查看完可注释</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing &#x3D; load_housing_data()</span><br><span class="line">print(housing.head())</span><br></pre></td></tr></table></figure>
<p> 总共有10个属性</p>
<p>c) 通过info（）方法可以快速获取数据集的简单描述，特别是总行数、每个属性的类型和非空值的数量<br> <code>print(housing.info())</code></p>
<p>d) 使用value_counts（）方法查看有多少种分类存在，每种类别下分别有多少个区域<br> <code>print(housing[&quot;ocean_proximity&quot;].value_counts())</code></p>
<p>e) 通过describe（）方法可以显示数值属性的摘要<br> <code>print(housing.describe())</code></p>
<p>f) 在整个数据集上调用hist（）方法，绘制每个属性的直方图</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">housing.hist(bins&#x3D;50, figsize&#x3D;(50,15))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建测试集</p>
<ul>
<li>理论上，创建测试集非常简单：只需要随机选择一些实例，通常是数据集的20%，然后将它们放在一边：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def split_train_test(data, test_ratio):</span><br><span class="line">    shuffled_indices &#x3D; np.random.permutation(len(data))</span><br><span class="line">    test_set_size &#x3D; int(len(data) * test_ratio)</span><br><span class="line">    test_indices &#x3D; shuffled_indices[:test_set_size]</span><br><span class="line">    train_indices &#x3D; shuffled_indices[test_set_size:]</span><br><span class="line">    return data.iloc[train_indices], data.iloc[test_indices]</span><br><span class="line"></span><br><span class="line">train_set, test_set &#x3D; split_train_test(housing, 0.2)</span><br><span class="line">print(len(train_set), &quot;train +&quot;, len(test_set), &quot;test&quot;)</span><br></pre></td></tr></table></figure></li>
<li>但这并不完美：如果你再运行一遍，它又会产生一个不同的数据集！这样下去，你（或者是你的机器学习算法）将会看到整个完整的数据集，而这正是创建测试集时需要避免的。常见的解决办法是每个实例都使用一个标识符（identifier）来决定是否进入测试集（假定每个实例都有一个唯一且不变的标识符）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import hashlib</span><br><span class="line">def test_set_check(identifier,test_ratio, hash):</span><br><span class="line">    return hash(np.int64(identifier)).digest()[-1] &lt; 256 * test_ratio</span><br><span class="line"></span><br><span class="line">def split_train_test_by_id(data, test_ratio, id_column, hash&#x3D;hashlib.md5):</span><br><span class="line">    ids &#x3D; data[id_column]</span><br><span class="line">    in_test_set &#x3D; ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))</span><br><span class="line">    return data.loc[~in_test_set], data.loc[in_test_set]</span><br><span class="line"></span><br><span class="line">#housing_with_id &#x3D; housing.reset_index()</span><br><span class="line">#housing_with_id[&quot;id&quot;] &#x3D; housing[&quot;longitude&quot;] * 1000 + housing[&quot;latitude&quot;]</span><br><span class="line">#train_set, test_set &#x3D; split_train_test_by_id(housing_with_id, 0.2, &quot;id&quot;)</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">train_set, test_set &#x3D; train_test_split(housing, test_size&#x3D;0.2, random&#x3D;42)</span><br></pre></td></tr></table></figure></li>
<li>分层抽样<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">housing[&quot;income_cat&quot;] &#x3D; np.ceil(housing[&quot;median_income&quot;] &#x2F; 1.5)</span><br><span class="line">housing[&quot;income_cat&quot;].where(housing[&quot;income_cat&quot;] &lt; 5, 5.0, inplace&#x3D;True)</span><br><span class="line">from sklearn.model_selection import StratifiedShuffleSplit</span><br><span class="line">split &#x3D; StratifiedShuffleSplit(n_splits&#x3D;1, test_size&#x3D;0.2, random_state&#x3D;42)</span><br><span class="line">for train_index, test_index in split.split(housing, housing[&quot;income_cat&quot;]):</span><br><span class="line">    strat_train_set &#x3D; housing.loc[train_index]</span><br><span class="line">    strat_test_set &#x3D; housing.loc[test_index]</span><br><span class="line">print(housing[&quot;income_cat&quot;].value_counts() &#x2F; len(housing))</span><br><span class="line">for set in (strat_train_set, strat_test_set):</span><br><span class="line">    set.drop([&quot;income_cat&quot;], axis&#x3D;1, inplace&#x3D;True)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>数据探索和可视化</p>
<ul>
<li>创建一个副本<code>housing = strat_train_set.copy()</code></li>
<li>将地理数据可视化<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#housing.plot(kind&#x3D;&quot;scatter&quot;, x&#x3D;&quot;longitude&quot;, y&#x3D;&quot;latitude&quot;)</span><br><span class="line">#housing.plot(kind&#x3D;&quot;scatter&quot;, x&#x3D;&quot;longitude&quot;, y&#x3D;&quot;latitude&quot;, alpha&#x3D;0.1)</span><br><span class="line">housing.plot(kind&#x3D;&quot;scatter&quot;, x&#x3D;&quot;longitude&quot;, y&#x3D;&quot;latitude&quot;, alpha&#x3D;0.4,</span><br><span class="line">s&#x3D;housing[&quot;population&quot;] &#x2F; 100, label&#x3D;&quot;population&quot;,</span><br><span class="line">c&#x3D;&quot;median_house_value&quot;, cmap&#x3D;plt.get_cmap(&quot;jet&quot;), colorbar&#x3D;True,)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li>
<li>寻找相关性<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#corr_matrix &#x3D; housing.corr()</span><br><span class="line">#print(corr_matrix[&quot;median_house_value&quot;].sort_values(ascending&#x3D;False))</span><br><span class="line">from pandas.plotting import scatter_matrix #少了tools</span><br><span class="line">attributes &#x3D; [&quot;median_house_value&quot;, &quot;median_income&quot;, &quot;total_rooms&quot;, &quot;housing_median_age&quot;]</span><br><span class="line">scatter_matrix(housing[attributes], figsize&#x3D;(12, 8))</span><br><span class="line">housing.plot(kind&#x3D;&quot;scatter&quot;, x&#x3D;&quot;median_income&quot;, y&#x3D;&quot;median_house_value&quot;, alpha&#x3D;0.1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>试验不同属性的组合</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">housing[&quot;rooms_per_household&quot;] &#x3D; housing[&quot;total_rooms&quot;]&#x2F;housing[&quot;households&quot;]</span><br><span class="line">housing[&quot;bedrooms_per_room&quot;] &#x3D; housing[&quot;total_bedrooms&quot;]&#x2F;housing[&quot;total_rooms&quot;]</span><br><span class="line">housing[&quot;population_per_household&quot;]&#x3D;housing[&quot;population&quot;]&#x2F;housing[&quot;households&quot;]</span><br><span class="line">corr_matrix &#x3D; housing.corr()</span><br><span class="line">print(corr_matrix[&quot;median_house_value&quot;].sort_values(ascending&#x3D;False))</span><br></pre></td></tr></table></figure>
</li>
<li><p>机器学习算法的数据准备</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing &#x3D; strat_train_set.drop(&quot;median_house_value&quot;, axis&#x3D;1)</span><br><span class="line">housing_labels &#x3D; strat_train_set[&quot;median_house_value&quot;].copy()</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据清理4选1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#housing.dropna(subset&#x3D;[&quot;total_bedrooms&quot;])    # option 1</span><br><span class="line">#housing.drop(&quot;total_bedrooms&quot;, axis&#x3D;1)       # option 2</span><br><span class="line">#median &#x3D; housing[&quot;total_bedrooms&quot;].median()</span><br><span class="line">#housing[&quot;total_bedrooms&quot;].fillna(median)     # option 3</span><br><span class="line"></span><br><span class="line">#option4: Scikit-Learn提供的imputer, 指定你要用属性的中位数值替换该属性的缺失值</span><br><span class="line">from sklearn.impute import SimpleImputer #与书中不同，进化了</span><br><span class="line">imputer &#x3D; SimpleImputer(strategy&#x3D;&quot;median&quot;)   #创建一个imputer实例</span><br><span class="line">housing_num &#x3D; housing.drop(&quot;ocean_proximity&quot;, axis&#x3D;1)   #创建一个没有文本属性的数据副本ocean_proximity</span><br><span class="line">imputer.fit(housing_num)   #使用fit（）方法将imputer实例适配到训练集</span><br><span class="line">#print(imputer.statistics_)</span><br><span class="line">#print(housing_num.median().values)</span><br><span class="line">X &#x3D; imputer.transform(housing_num)   #替换</span><br><span class="line">housing_tr &#x3D; pd.DataFrame(X, columns&#x3D;housing_num.columns)   #放回Pandas DataFrame</span><br></pre></td></tr></table></figure>
</li>
<li><p>处理文本和分类属性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#先将这些文本标签转化为数字，Scikit-Learn为这类任务提供了一个转换器LabelEncoder：</span><br><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line">encoder &#x3D; LabelEncoder()</span><br><span class="line">housing_cat &#x3D; housing[&quot;ocean_proximity&quot;]</span><br><span class="line">housing_cat_encoded &#x3D; encoder.fit_transform(housing_cat)</span><br><span class="line">#print(housing_cat_encoded)</span><br><span class="line">#print(encoder.classes_)</span><br><span class="line"></span><br><span class="line">#Scikit-Learn提供了一个OneHotEncoder编码器，可以将整数分类值转换为独热向量</span><br><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line">encoder &#x3D; OneHotEncoder()</span><br><span class="line">housing_cat_1hot &#x3D; encoder.fit_transform(housing_cat_encoded.reshape(-1,1))</span><br><span class="line">#print(housing_cat_1hot.toarray())</span><br><span class="line"></span><br><span class="line">#使用LabelBinarizer类可以一次性完成两个转换</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line">encoder &#x3D; LabelBinarizer()</span><br><span class="line">housing_cat_1hot &#x3D; encoder.fit_transform(housing_cat)</span><br><span class="line">print(housing_cat_1hot)</span><br></pre></td></tr></table></figure>
</li>
<li><p>自定义转换器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, household_ix &#x3D; 3, 4, 5, 6</span><br><span class="line">class CombinedAttributesAdder(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, add_bedrooms_per_room &#x3D; True): # no *args or **kargs</span><br><span class="line">        self.add_bedrooms_per_room &#x3D; add_bedrooms_per_room</span><br><span class="line">    def fit(self, X, y&#x3D;None):</span><br><span class="line">        return self    #nothing else to do</span><br><span class="line">    def transform(self, X, y&#x3D;None):</span><br><span class="line">        rooms_per_household &#x3D; X[:, rooms_ix] &#x2F; X[:, household_ix]</span><br><span class="line">        population_per_household &#x3D; X[:, population_ix] &#x2F; X[:, household_ix]</span><br><span class="line">        if self.add_bedrooms_per_room:</span><br><span class="line">            bedrooms_per_room &#x3D; X[:, bedrooms_ix] &#x2F; X[:, rooms_ix]</span><br><span class="line">            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]</span><br><span class="line">        else:</span><br><span class="line">            return np.c_[X, rooms_per_household, population_per_household]</span><br><span class="line">attr_adder &#x3D; CombinedAttributesAdder(add_bedrooms_per_room&#x3D;False)</span><br><span class="line">housing_extra_attribs &#x3D; attr_adder.transform(housing.values)</span><br></pre></td></tr></table></figure>
</li>
<li><p>转换流水线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">num_pipeline &#x3D; Pipeline([</span><br><span class="line">    (&#39;imputer&#39;, SimpleImputer(strategy&#x3D;&quot;median&quot;)),</span><br><span class="line">    (&#39;attribs_adder&#39;, CombinedAttributesAdder()),</span><br><span class="line">    (&#39;std_scaler&#39;, StandardScaler()),</span><br><span class="line">    ])</span><br><span class="line">housing_num_tr &#x3D; num_pipeline.fit_transform(housing_num)</span><br><span class="line">#print(housing_num_tr)</span><br><span class="line"></span><br><span class="line">from sklearn.compose import ColumnTransformer</span><br><span class="line">num_attribs &#x3D; list(housing_num)</span><br><span class="line">cat_attribs &#x3D; [&quot;ocean_proximity&quot;]</span><br><span class="line"></span><br><span class="line">full_pipeline &#x3D; ColumnTransformer([</span><br><span class="line">    (&quot;num&quot;, num_pipeline, num_attribs),</span><br><span class="line">    (&quot;cat&quot;, OneHotEncoder(), cat_attribs),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">housing_prepared &#x3D; full_pipeline.fit_transform(housing)</span><br><span class="line">#print(housing_prepared)</span><br><span class="line">#print(housing_prepared.shape)</span><br></pre></td></tr></table></figure>
</li>
<li><p>选择和训练模型</p>
<ul>
<li>训练一个线性回归模型：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">lin_reg &#x3D; LinearRegression()</span><br><span class="line">lin_reg.fit(housing_prepared, housing_labels)</span><br><span class="line">#print(lin_reg)</span><br><span class="line">#实例试试</span><br><span class="line">some_data &#x3D; housing.iloc[:5]</span><br><span class="line">some_labels &#x3D; housing_labels.iloc[:5]</span><br><span class="line">some_data_prepared &#x3D; full_pipeline.transform(some_data)</span><br><span class="line">#print(&quot;Predictions:&quot;, lin_reg.predict(some_data_prepared))</span><br><span class="line">#print(&quot;Labels:&quot;, list(some_labels))</span><br><span class="line">#print(some_data_prepared)</span><br></pre></td></tr></table></figure></li>
<li>使用Scikit-Learn的mean_squared_error函数来测量整个训练集上回归模型的RMSE：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">housing_predictions &#x3D; lin_reg.predict(housing_prepared)</span><br><span class="line">lin_mse &#x3D; mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">lin_rmse &#x3D; np.sqrt(lin_mse)</span><br><span class="line">#print(lin_rmse)</span><br><span class="line">from sklearn.metrics import mean_absolute_error</span><br><span class="line">lin_mae &#x3D; mean_absolute_error(housing_labels, housing_predictions)</span><br><span class="line">#print(lin_mae)</span><br></pre></td></tr></table></figure></li>
<li>我们来训练一个(决策树)DecisionTreeRegressor。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeRegressor</span><br><span class="line">tree_reg &#x3D; DecisionTreeRegressor(random_state&#x3D;42)</span><br><span class="line">tree_reg.fit(housing_prepared, housing_labels)</span><br><span class="line">housing_predictions &#x3D; tree_reg.predict(housing_prepared)</span><br><span class="line">tree_mse &#x3D; mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">tree_rmse &#x3D; np.sqrt(tree_mse)</span><br><span class="line">#print(tree_rmse)    #可能对数据严重过度拟合</span><br></pre></td></tr></table></figure></li>
<li>使用交叉验证来更好地进行评估<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">scores &#x3D; cross_val_score(tree_reg, housing_prepared, housing_labels, scoring&#x3D;&quot;neg_mean_squared_error&quot;, cv&#x3D;10)</span><br><span class="line">tree_rmse_scores &#x3D; np.sqrt(-scores)</span><br><span class="line"></span><br><span class="line">def display_scores(scores):</span><br><span class="line">print(&quot;Scores:&quot;, scores)</span><br><span class="line">print(&quot;Mean:&quot;, scores.mean())</span><br><span class="line">print(&quot;Standard deviation:&quot;, scores.std())</span><br><span class="line">#display_scores(tree_rmse_scores)</span><br></pre></td></tr></table></figure></li>
<li>计算一下线性回归模型的评分<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lin_scores &#x3D; cross_val_score(lin_reg, housing_prepared, housing_labels, scoring&#x3D;&quot;neg_mean_squared_error&quot;, cv&#x3D;10)</span><br><span class="line">lin_rmse_scores &#x3D; np.sqrt(-lin_scores)</span><br><span class="line">#display_scores(lin_rmse_scores)</span><br></pre></td></tr></table></figure></li>
<li>随机森林模型RandomForestRegressor<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">forest_reg &#x3D; RandomForestRegressor(n_estimators&#x3D;10, random_state&#x3D;42)</span><br><span class="line">forest_reg.fit(housing_prepared, housing_labels)</span><br><span class="line">housing_predictions &#x3D; forest_reg.predict(housing_prepared)</span><br><span class="line">forest_mse &#x3D; mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">forest_rmse &#x3D; np.sqrt(forest_mse)</span><br><span class="line">#print(forest_rmse)</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">forest_scores &#x3D; cross_val_score(forest_reg, housing_prepared, housing_labels, scoring&#x3D;&quot;neg_mean_squared_error&quot;, cv&#x3D;10)</span><br><span class="line">forest_rmse_scores &#x3D; np.sqrt(-forest_scores)</span><br><span class="line">#display_scores(forest_rmse_scores)</span><br><span class="line">scores &#x3D; cross_val_score(lin_reg, housing_prepared, housing_labels, scoring&#x3D;&quot;neg_mean_squared_error&quot;, cv&#x3D;10)</span><br><span class="line">#print(pd.Series(np.sqrt(-scores)).describe())</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>微调模型</p>
</li>
<li><p>网格搜索</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#你可以用Scikit-Learn的GridSearchCV来替你进行探索。你所要做的只是告诉它你要进行实验的超参数是什么，以及需要尝试的值，它将会使用交叉验证来评估超参数值的所有可能的组合。</span><br><span class="line">#下面这段代码搜索RandomForestRegressor的超参数值的最佳组合:</span><br><span class="line">#当你不知道超参数应该赋什么值时，一个简单的方法是连续尝试10的幂次方</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">param_grid &#x3D; [</span><br><span class="line">    &#123;&#39;n_estimators&#39;: [3, 10, 30], &#39;max_features&#39;: [2, 4, 6, 8]&#125;, # try 12 (3×4) combinations of hyperparameters</span><br><span class="line">    &#123;&#39;bootstrap&#39;: [False], &#39;n_estimators&#39;: [3, 10], &#39;max_features&#39;: [2, 3, 4]&#125;, # then try 6 (2×3) combinations with bootstrap set as False</span><br><span class="line">]</span><br><span class="line">forest_reg &#x3D; RandomForestRegressor()</span><br><span class="line">grid_search &#x3D; GridSearchCV(forest_reg, param_grid, cv&#x3D;5, scoring&#x3D;&#39;neg_mean_squared_error&#39;)</span><br><span class="line">grid_search.fit(housing_prepared, housing_labels)</span><br><span class="line">#print(grid_search.best_params_)</span><br><span class="line">#print(grid_search.best_estimator_)</span><br><span class="line"></span><br><span class="line">cvres &#x3D; grid_search.cv_results_</span><br><span class="line">for mean_score, params in zip(cvres[&quot;mean_test_score&quot;], cvres[&quot;params&quot;]):</span><br><span class="line">   print(np.sqrt(-mean_score), params)</span><br><span class="line">print(pd.DataFrame(grid_search.cv_results_))</span><br><span class="line">#随机搜索</span><br><span class="line">#集成方法</span><br></pre></td></tr></table></figure>
</li>
<li><p>分析最佳模型及其错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">feature_importances &#x3D; grid_search.best_estimator_.feature_importances_</span><br><span class="line">#print(feature_importances)</span><br><span class="line">#将这些重要性分数显示在对应的属性名称旁边：</span><br><span class="line">extra_attribs &#x3D; [&quot;rooms_per_hhold&quot;, &quot;pop_per_hhold&quot;, &quot;bedrooms_per_room&quot;]</span><br><span class="line">#cat_encoder &#x3D; cat_pipeline.named_steps[&quot;cat_encoder&quot;] # old solution</span><br><span class="line">cat_encoder &#x3D; full_pipeline.named_transformers_[&quot;cat&quot;]</span><br><span class="line">cat_one_hot_attribs &#x3D; list(cat_encoder.categories_[0])</span><br><span class="line">attributes &#x3D; num_attribs + extra_attribs + cat_one_hot_attribs</span><br><span class="line">sorted(zip(feature_importances, attributes), reverse&#x3D;True)</span><br><span class="line">#print(sorted(zip(feature_importances, attributes), reverse&#x3D;True))</span><br><span class="line">#通过测试集评估系统</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">final_model &#x3D; grid_search.best_estimator_</span><br><span class="line">X_test &#x3D; strat_test_set.drop(&quot;median_house_value&quot;, axis&#x3D;1)</span><br><span class="line">y_test &#x3D; strat_test_set[&quot;median_house_value&quot;].copy()</span><br><span class="line">X_test_prepared &#x3D; full_pipeline.transform(X_test)</span><br><span class="line">final_predictions &#x3D; final_model.predict(X_test_prepared)</span><br><span class="line">final_mse &#x3D; mean_squared_error(y_test, final_predictions)</span><br><span class="line">final_rmse &#x3D; np.sqrt(final_mse)</span><br><span class="line">#print(final_rmse)</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动、监控和维护系统</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-c语言笔试准备" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/06/c%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AF%95%E5%87%86%E5%A4%87/" class="article-date">
      <time datetime="2020-03-06T12:23:02.000Z" itemprop="datePublished">2020-03-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/06/c%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AF%95%E5%87%86%E5%A4%87/">c语言笔试准备</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <ol>
<li><p>若以下说明语句:char x; float y; double z; 则表达式x-y+z的类型为（double） 。<br>字节转换从低到高 char–&gt;float–&gt;short–&gt;int–&gt;double<br>规律：占用字节数小的类型在与占用字节数大的类型运算时会被转化为占用<strong>字节数大</strong>的类型。</p>
</li>
<li><p>设int a=3,b=5,m，执行表达式m=a&lt;=3&amp;&amp;a+b&lt;8后，m的值为 （0）<br><strong>！ &gt; 算术运算符 &gt; 关系运算符 &gt; &amp;&amp; &gt; || &gt; 赋值运算符</strong><br>m是整型，因此将false转为整型即为0。<br>m=1&amp;&amp;0<br>m=0</p>
</li>
<li><p>用数组名作函数实参时，形参可以用同类型的指针变量。<br>比如数组<br>int S[10];<br>数组名S可以理解为就是指向数组首地址的指针，即 S 和 &amp;S[0] 等价，*S和S[0]等价， 数组名作函数实参时，参数类型就是指向整型的指针</p>
</li>
<li><p>字符型数据在计算机内部是以ASCII码存储的，数字、英文大写字母和小写字母在ASCII码表中都是连续的。<strong>数字字符‘0’<del>‘9’是48</del>57</strong>，大写字母A～Z是从65～90，<strong>小写字母a～z是从97～122</strong>。</p>
</li>
<li><p>数组可以在<strong>定义</strong>时整体赋初值，但不能在赋值语句中整体赋值。</p>
</li>
<li><p>继承方式和可见性</p>
<ul>
<li>公有继承意味着继承派生类的类能访问基类的公有和保护成员。私有继承意味着继承派生类的类也不能访问基类的成员。保护继承意味着继承派生类的类能访问基类的公有和保护方法。</li>
<li>默认为私有继承，但常用的却是公有继承。</li>
<li>基类的私有成员在派生类中都是不可见的，如果一个派生类要访问基类中声明的私有成员，可以将这个派生类声明为友元。</li>
<li>公有继承时，同样继承了基类的私有成员，对基类的公有成员和保护成员的访问属性不变，派生类的新增成员可以访问基类的公有成员和保护成员，但是访问不了基类的私有成员。派生类的对象只能访问派生类的公有成员（包括继承的公有成员），访问不了保护成员和私有成员。</li>
</ul>
</li>
<li><p>可以把<code>z=x&gt;y? x : y</code>理解为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if(x&gt;y)&#123;</span><br><span class="line">z&#x3D;x；</span><br><span class="line">&#125;else&#123;</span><br><span class="line">z&#x3D;y；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于条件表达式b ? x : y，先计算条件b，然后进行判断。如果b的值为true，计算x的值，运算结果为x的值；否则，计算y的值，运算结果为y的值。一个条件表达式绝不会既计算x，又计算y。条件运算符是右结合的，也就是说，从右向左分组计算</p>
</li>
<li><p>auto被解释为一个自动存储变量的关键字，也就是申明一块临时的变量内存。<br>其中auto和register对应自动存储期。具有自动存储期的变量在进入声明该变量的程序块时被建立，它在该程序块活动时存在，退出该程序块时撤销。</p>
</li>
<li><p>register:这个关键字命令编译器尽可能的将变量存在CPU内部寄存器中而不是通过内存寻址访问以提高效率。如果一个变量被register来修饰，就意味着该变量作为一个寄存器变量，让该变量的访问速度达到最快。</p>
</li>
<li><p>全局变量在静态区;局部变量在动态区;static变量在静态区 </p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c%E8%AF%AD%E8%A8%80/" rel="tag">c语言</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-c语言面试准备" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/05/c%E8%AF%AD%E8%A8%80%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/" class="article-date">
      <time datetime="2020-03-04T16:00:00.000Z" itemprop="datePublished">2020-03-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/05/c%E8%AF%AD%E8%A8%80%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/">c语言面试准备</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <ol>
<li><p><strong>#define</strong>不能以分号结束，在宏中把参数用括号括起来</p>
<ul>
<li>写一个“标准”宏,这个宏输入两个参数并返回较小的：<code>#define MIN(x, y) ((x)&lt; (y)?(x):(y)) //结尾没有;</code></li>
<li>#是把宏参数转化为字符串的运算符，##是把两个宏参数连接的运算符。</li>
<li>为避免头文件my_ head.h被重复包含，可在其中使用条件编译:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#ifndef_ MY_ HEAD H</span><br><span class="line">#define_ MY_ HEAD_ H &#x2F;*空宏*&#x2F;</span><br><span class="line">&#x2F;*其他语句*&#x2F;</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>预处理器直接计算常数表达式的值</p>
</li>
<li><p>死循环：while(1){}或for(;;){} </p>
<ul>
<li>两者相比for里面为空，编译执行之后没有判断的语句，而 while(1)始终都会有执行判断 1 = true，所以在单片机这种低速的、内存资源不多的环境，for(;;)是更好的选择。少执行判断语句，直接跳转（jump）到循环开始的代码继续执行。</li>
</ul>
</li>
<li><p>用变量a给出下面的定义 </p>
<ul>
<li>一个整型数: <code>int a</code></li>
<li>一个指向整型数的指针: <code>int *a</code></li>
<li>一个指向指针的指针，它指向的指针是指向一个整型数: <code>int **a</code></li>
<li>一个有10个整型数的数组: <code>int a[10]</code></li>
<li>一个有<u><strong>10个指针的数组，该指针是指向一个整型数的</strong></u>: <code>int *a[10]</code></li>
<li>一个指向有<u><strong>10个整型数数组的指针</strong></u>: <code>int (*a)[10]</code></li>
<li>一个指向<strong>函数</strong>的指针，该函数有一个整型参数并返回一个整型数： <code>int (*a)(int)</code></li>
<li>一个有10个指针的数组，该指针指向一个函数，该函数有一个整型参数并返回一个整型数： <code>int (*a[10])(int)</code></li>
</ul>
</li>
<li><p>关键字<strong>static</strong>的作用</p>
<ul>
<li>在函数体，一个被声明为静态的变量在这一函数被调用过程中维持其值不变。 </li>
<li>在模块内（但在函数体外），一个被声明为静态的<strong>变量</strong>可以被模块内所用函数<strong>访问</strong>，但不能被模块外其它函数访问。它是一个本地的全局变量。 </li>
<li>在模块内，一个被声明为静态的<strong>函数</strong>只可被这一模块内的其它函数<strong>调用</strong>。那就是，这个函数被限制在声明它的模块的本地范围内使用。</li>
</ul>
</li>
<li><p>关键字const有什么含意？</p>
<ul>
<li>它限定一个变量<strong>不允许被改变</strong>，产生静态作用。使用const在一定程度上可以提高程序的<strong>安全性和可靠性</strong>。另外，在观看别人代码的时候，清晰理解const所起的作用，对理解对方的程序也有一定帮助。</li>
<li>const 推出的初始目的，正是为了<strong>取代预编译指令，消除它的缺点，同时继承它的优点</strong>。</li>
<li>便于进行类型检查，使编译器对处理内容有更多了解，消除了一些隐患。</li>
<li>可以避免意义模糊的数字出现，同样可以很方便地进行参数的调整和修改。 同宏定义一样，可以做到不变则已，一变都变！</li>
<li>可以保护被修饰的东西，防止意外的修改，增强程序的健壮性,减少bug。</li>
<li>可以节省空间，避免不必要的内存分配。</li>
<li>意味着<strong>只读</strong>。<ul>
<li><code>const int a</code>； 或<code>int const a</code>； 表示a是一个常整型数。</li>
<li><code>const int *a</code>; 意味着a是一个指向常整型数的指针（<strong>整型数是不可修改的，但指针可以</strong></u>）。</li>
<li><code>int * const a</code>; a是一个指向整型数的常指针（<strong>指针指向的整型数是可以修改的，但指针是不可修改的</strong>）。</li>
<li><code>int const * a const</code>; 意味着a是一个指向常整型数的常指针（也就是说，<strong>指针指向的整型数是不可修改的，同时指针也是不可修改的</strong>）。</li>
<li><code>int fun(const int a);</code>或<code>int fun(const char *str);</code>修饰函数形参,使得形参在函数内不能被修改，表示输入参数。</li>
<li><code>const char *getstr(void);</code>使用: <code>const *str= getstr);</code><br><code>const int getint(void);</code>使用: <code>const int a =getint();</code>修饰函数返回值，使得函数的返回值不能被修改。</li>
</ul>
</li>
</ul>
</li>
<li><p>关键字volatile有什么含义？</p>
<ul>
<li>一个定义为volatile的变量是说<strong>这变量可能会被意想不到地改变</strong>，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地<strong>重新读取这个变量的值，而不是使用保存在寄存器里的备份</strong>。下面是volatile变量的几个例子：<ul>
<li>并行设备的硬件寄存器（如：状态寄存器） </li>
<li>一个中断服务子程序中会访问到的非自动变量(Non-automatic variables) </li>
<li>多线程应用中被几个任务共享的变量</li>
</ul>
</li>
<li>搞嵌入式的家伙们经常同硬件、中断、RTOS等等打交道，所有这些都要求用到volatile变量。</li>
<li>问题<ol>
<li>一个参数既可以是const还可以是volatile吗？解释为什么。<ul>
<li>一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。 </li>
</ul>
</li>
<li>一个指针可以是volatile 吗？解释为什么。 <ul>
<li>一个例子是当一个中服务子程序修该一个指向一个buffer的指针时。</li>
</ul>
</li>
</ol>
</li>
<li>volatile指定的关键字可能被系统、硬件、进程/线程改变,强制编译器每次从内存中取得该变量的值，而不是从被优化后的寄存器中读取。例子:硬件时钟;多线程中被多个任务共享的变量等。</li>
</ul>
</li>
<li><p>extern关键宇的作用：</p>
<ul>
<li>于修饰变量或函数，表明该变量或函数都是在别的文件中定义的,提示编译器在其他文件找定义。</li>
<li><code>extern &quot;C&quot;</code>的作用就是为了能够正确实现C+ +代码调其他C语言代码。</li>
</ul>
</li>
<li><p>要求设置一绝对地址为0x67a9的整型变量的值为0xaa66。编译器是一个纯粹的ANSI编译器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int *ptr; </span><br><span class="line">ptr &#x3D; (int *)0x67a9; </span><br><span class="line">*ptr &#x3D; 0xaa55;</span><br></pre></td></tr></table></figure>
</li>
<li><p>有关中断：</p>
<ul>
<li>ISR 不能返回一个值。如果你不懂这个，那么你不会被雇用。 </li>
<li>ISR 不能传递参数。如果你没有看到这一点，你被雇用的机会等同第一项。 </li>
<li>在许多的处理器/编译器中，浮点一般都是不可重入的。有些处理器/编译器需要让额处的寄存器入栈，有些处理器/编译器就是不允许在ISR中做浮点运算。此外，ISR应该是短而有效率的，在ISR中做浮点运算是不明智的。 </li>
<li>与第三点一脉相承，printf()经常有重入和性能上的问题。</li>
</ul>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c%E8%AF%AD%E8%A8%80/" rel="tag">c语言</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/03/hello-world/" class="article-date">
      <time datetime="2020-03-02T18:17:52.529Z" itemprop="datePublished">2020-03-03</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/03/hello-world/">Hello World</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2020 KissingIce
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 6;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>